[general]
dataset_lenght = 1000
dataset_depth = 7

[gym_env]
kernel_size = 3
step_reward = False
step_r_metric = Trace_distance
#or "mse"
neg_reward = -0.1
pos_reward = 0.1
action_penality= 0.
#0.001 works fine with mse reward
action_space = Box 
#or "Binary"


[noise]
primitive_gates = ["RZ", "RX","CZ"]
channels = ["DepolarizingChannel","ResetChannel"]
coherent_channels = ["epsilon_z","epsilon_x"]
t1 = 1
t2 = 1
thermal_time = 0.07
dep_lambda = 0.05
p0 = 0.1
epsilon_x = 0.15
epsilon_z = 0.1
std_noise = True
coherent_noise = True


[policy]
save_best_model = True
plot_results = True
model_name = 3Q_dep-term_logReward
plot_name = dep-term_logReward

[reward]

reward_type = Log


